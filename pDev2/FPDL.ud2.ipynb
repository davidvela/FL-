{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import operator\n",
    "from types import *\n",
    "from collections import Counter\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set desc!\n"
     ]
    }
   ],
   "source": [
    "DESC = \"FLALL2\"\n",
    "\n",
    "LOG = \"../../LOG.txt\"\n",
    "LOGDIR     = \"../../dmodels/\"\n",
    "LOGDAT     = \"../../data/\"\n",
    "DSJ        = \"/data_json.txt\"\n",
    "DSC        = \"/datasc.csv\"   \n",
    "DC         = \"/datac.csv\"\n",
    "DL         = \"/datal.csv\"\n",
    "\n",
    "print(\"set desc!\")\n",
    "\n",
    "COL_DS     = LOGDAT + DESC + DC \n",
    "ALL_DSJ    = LOGDAT + DESC + DSJ \n",
    "ALL_DS     = LOGDAT + DESC + DSC \n",
    "pp_abs     = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FD\n",
    "def feed_data(dataJJ, d_st = False, pand=False, p_col = False,  p_all = True, p_down=False):\n",
    "    #index_col=0 if p_abs else 2 #abs=F => 2 == 6D\n",
    "    index_col = 2 #name - num, abs = cc\n",
    "    # col_df = pd.read_csv(COL_DS, index_col=index_col, sep=',', usecols=[0,1,2,3])    \n",
    "    col_df = pd.read_csv(COL_DS, index_col=index_col, sep=',', usecols=[0,1,2,3])    \n",
    "    col_df = col_df.fillna(0)\n",
    "    print(\"input-no={}\".format( len(col_df )))\n",
    "    \n",
    "    try:\n",
    "        indx = dst.columns\n",
    "        indx = indx.delete(2)\n",
    "    except NameError:  #TypeError\n",
    "        indx = col_df.index\n",
    "        indx = indx.insert(0, \"M\")\n",
    "        indx = indx.insert(1, \"FP\")  # indx = indx.insert(2, \"FP_P\")\n",
    "    print(type(indx[5]));print(indx[5]);\n",
    "    if p_col:    \n",
    "        dataTest_label = []\n",
    "        dataJJ = \"[\"\n",
    "        for i in range(len(col_df)): \n",
    "            #fpp = cc( int(  col_df.iloc[i][\"fp\"]  ))\n",
    "            fpp = int(  col_df.iloc[i][\"fp\"]  )\n",
    "            dataTest_label.append(  fpp ) \n",
    "            #dataJJ += '{\"m\":\"'+str(i)+'\",'+'\"'+str(col_df.iloc[i].name)+'\"'+\":1},\"\n",
    "            dataJJ += '{\"m\":\"'+str(col_df.iloc[i].name)+'\",'+'\"'+str(col_df.iloc[i].name)+'\"'+\":1},\"\n",
    "        dataJJ += '{\"m\":\"0\"}]';  dataTest_label.append(0)\n",
    "        # dataJJ += ']'\n",
    "        dataJJ = json.loads(dataJJ)\n",
    "\n",
    "    if pd.core.indexes.numeric.is_integer_dtype(col_df.index):  isInt = True\n",
    "    else: isInt = False\n",
    "\n",
    "    json_df  = pd.DataFrame(columns=indx); df_entry = pd.Series(index=indx)\n",
    "    \n",
    "    df_entry = df_entry.fillna(0) \n",
    "    ccount = Counter()\n",
    "\n",
    "    if(isinstance(dataJJ, list)):json_data = dataJJ\n",
    "    else: json_str=open(dataJJ).read();  json_data = json.loads(json_str)\n",
    "    \n",
    "    if p_all: ll = range(len(json_data))\n",
    "    else: ll = range(ll_st, ll_en)\n",
    "    # pp_abs = True  # test \n",
    "    print(\"PP_ABS = \" + str(pp_abs));    \n",
    "    #for i in range(2):\n",
    "    for i in ll: # print(i)\n",
    "        df_entry *= 0\n",
    "        m = str(json_data[i][\"m\"])\n",
    "        df_entry.name = m\n",
    "        df_entry[\"M\"] = m\n",
    "        for key in json_data[i]:\n",
    "            if key != \"m\": \n",
    "                # key_wz = key if pp_abs else int(key)  #str(int(key)) FRFLO - int // FRALL str!\n",
    "                \n",
    "                if isInt : key_wz = int(key)            # if comp NOT conatin letters\n",
    "                else: key_wz = str(key) #str(key)       # if comp contains letters\n",
    "                # print(type(key))                \n",
    "                try: #filling of key - experimental or COMP \n",
    "                    if d_st:\n",
    "                        ds_comp = col_df.loc[key_wz] #print(ds_comp) # THIS IS THE MOST TIME CONSUMING OP. \n",
    "                        col_key = ds_comp.cc if pp_abs else  str(ds_comp.name) #\n",
    "                    else: \n",
    "                        col_key = int(key) #str(int(key)) \n",
    "                    \n",
    "                    col_key = int(col_key) # or int... \n",
    "                    #if isInt : col_key = int(col_key)     # if comp NOT conatin letters\n",
    "                    #else: key_wz = col_key = str(col_key)   \n",
    "\n",
    "                    df_entry[col_key] =  np.float32(json_data[i][key]) # df_entry.loc[col_key]\n",
    "                    # print(col_key); print(type(col_key))\n",
    "                except: \n",
    "                    if d_st: print(\"m:{}-c:{} not included\" .format(m, key_wz)); ccount[key_wz] +=1\n",
    "        # ONLY USED TO CONVERT JSON TO EXCEL => EXCEL WILL BE SMALLER\n",
    "        if p_down: df_entry = df_entry.replace(0, np.nan) # DANGER !!! \n",
    "\n",
    "        json_df = json_df.append(df_entry,ignore_index=False)\n",
    "        if i % 1000 == 0: print(\"cycle: {}\".format(i))\n",
    "    print(\"Counter of comp. not included :\"); print(ccount) # print(len(ccount))\n",
    " \n",
    "        \n",
    "    if p_col:  \n",
    "        json_df[\"FP\"] = dataTest_label\n",
    "    \n",
    "    if pand:  return json_df\n",
    "    else:     \n",
    "        if p_col: return json_df.iloc[:,3:].as_matrix().tolist(), dataTest_label\n",
    "        else:     return json_df.iloc[:,3:].as_matrix().tolist() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tests(url_test='url', force=False, pp_excel=False, pDataFile = \"data_jsonX.txt\", pLabelFile = \"datalX.csv\", p_dst=True, p_all = True ): \n",
    "    global dsp, flag_dsp \n",
    "    print(pp_excel)\n",
    "    if flag_dsp or force: \n",
    "        flag_dsp = False\n",
    "        # 2 -- READ EXCEL \n",
    "        if pp_excel: dsp = pd.read_csv( tf.gfile.Open( LOGDAT + DESC + \"/datasc_tx.csv\"  ), sep=None, skipinitialspace=True,  engine=\"python\" )\n",
    "        else: # 1 -- READ JSON \n",
    "            if url_test != 'url':           # test  file \n",
    "                json_data = url_test + pDataFile\n",
    "                tmpLab = pd.read_csv( url_test + pLabelFile, sep=',', usecols=[0,1])    \n",
    "                tmpLab = tmpLab.loc[:,'fp'].tolist()\n",
    "                #DESC     = \"FREXP1_X\"\n",
    "            else:                           # get data test JSON = url\n",
    "                json_str, tmpLab = get_data_test(1) \n",
    "                json_data = json.loads(json_str)\n",
    "                #DESC =  'matnrList...'\n",
    "        \n",
    "            dsp = feed_data(json_data ,pand=True, d_st=p_dst, p_all = p_all)       #d_st = display status\n",
    "            \n",
    "            if p_all: dsp[\"FP\"] = tmpLab      #normalize(2)  # del dsp['FP_P']\n",
    "        # if p_all: dsp.insert(2, 'FP_P', dsp['FP'].map(lambda x: cc( x )))  \n",
    "\n",
    "    else:    \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testsJ2(pDesc, excel=True, split = False, pTest = True):\n",
    "    start = time.time()\n",
    "    print(\"___JSON!___\" +  datetime.now().strftime('%H:%M:%S')  )\n",
    "\n",
    "    # url_test = LOGDAT + \"FREXP1/\" ; dataFile = \"data_jsonX.txt\";  labelFile = \"datalX.csv\" ;   #url_test = \"url\"\n",
    "    # setDESC(\"FLALL2\"); url_test = LOGDAT + \"FLALL2/\" ; dataFile = \"frall2_json.txt\"; labelFile = \"datal.csv\" \n",
    "    url_test = LOGDAT + pDesc + \"/\" ; dataFile = \"frall2_json.txt\"; labelFile = \"datal.csv\" \n",
    "    \n",
    "    if pTest:                                               #   disp   all\n",
    "        get_tests(url_test, False, False, dataFile, labelFile, False, False ); tmp = dsp\n",
    "    else: \n",
    "        pass\n",
    "        #get_columns(False, False, True); tmp = dsc\n",
    "    \n",
    "    # del tmp['FP_P']\n",
    "\n",
    "    #if split: pass # separate betweent TR and EV     \n",
    "\n",
    "    print(\"data read - time:{}\" .format(float(time.time() - start) ))\n",
    "    down_excel(tmp,  excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_excel(data, excel_flag): \n",
    "    if excel_flag: \n",
    "        writer = pd.ExcelWriter(LOGDAT+'json2excel.xlsx')\n",
    "        data.to_excel(writer, sheet_name='Sheet1')\n",
    "        writer.save()\n",
    "        print(\"JSON downloaded into excel! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main1():    # convert json2excel_base\n",
    "    print(\"hi1\")\n",
    "    # md.mainRead2(ALL_DS, 1, 2, all = True, shuffle = True  ) \n",
    "    #pDesc = \"FLALL2\"\n",
    "    #setDESC(pDesc)\n",
    "    # mainRead2(ALL_DS, 1, 2, all = False ) # For testing I am forced to used JSON - column names and order may be different! \n",
    "    testsJ2(pDesc = pDesc, excel=True, split = False, pTest = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi1\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'testsJ2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-db358e78cfc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# mainRead2(ALL_DS, 1, 2, all = True, shuffle = False )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmain1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-c1ec466a4649>\u001b[0m in \u001b[0;36mmain1\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#setDESC(pDesc)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# mainRead2(ALL_DS, 1, 2, all = False ) # For testing I am forced to used JSON - column names and order may be different!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtestsJ2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpDesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpDesc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexcel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'testsJ2' is not defined"
     ]
    }
   ],
   "source": [
    "# mainRead2(ALL_DS, 1, 2, all = True, shuffle = False ) \n",
    "main1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_col = 2\n",
    "tol_df = pd.read_csv(COL_DS, index_col=index_col, sep=',', usecols=[0,1,2,3])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tol_df.iloc[0][\"fp\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
